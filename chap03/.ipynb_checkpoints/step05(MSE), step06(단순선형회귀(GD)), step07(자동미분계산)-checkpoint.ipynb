{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145f6d4f",
   "metadata": {},
   "source": [
    "회귀는 훈련 데이터의 오차를 최소화하는 모델을 찾는 방법이다. 즉, 데이터의 모델을 찾는 문제이다.\n",
    "\n",
    "선형대수의 최소자승법으로도 선형 회귀 모델의 해를 계산할 수 있지만\n",
    "여기서는 뉴런을 이용한 최적화 알고리즘으로 손실함수를 반복적으로 최소화하여 선형 회귀의 해를 계산할 것이다.\n",
    "\n",
    "회귀는 입력, 출력의 목표값의 훈련데이터로 학습하는 **감독학습** 방법이다.\n",
    "\n",
    "### 구성 데이터\n",
    "훈련데이터(X, t)는 입력 **X**와 목표값 **t**로 구성된다.\n",
    "\n",
    "**모델 파라미터**(W, b)를 초기화하고, 출력인 **예측값 y**를 계산하고\n",
    "\n",
    "**error**(t, y)의 오차를 최소화하도록 파라미터를 반복 학습한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1fbe3",
   "metadata": {},
   "source": [
    "# Step05 평균 제곱 오차 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f759a8e",
   "metadata": {},
   "source": [
    "## step05_01\n",
    "### Numpy: 평균 제곱 오차(MSE)\n",
    "MSE는 예측값(y)와 목표값(t)를 뺀 값에서 제곱을 하여 합을 구한 뒤에 목표값(t)의 사이즈 만큼 뺀다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143b9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(t, y1)= 1.875\n",
      "MSE(t, y2)= 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MSE(y, t):\n",
    "    return np.sum((y-t)**2)/t.size\n",
    "\n",
    "t = np.array([1, 2, 3, 4])\n",
    "y1 = np.array([0.5, 1, 1.5, 2])\n",
    "print(\"MSE(t, y1)=\", MSE(t, y1))\n",
    "\n",
    "y2 = np.array([0.5, 1.5, 2.5, 3.5])\n",
    "print(\"MSE(t, y2)=\", MSE(t, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f32e98",
   "metadata": {},
   "source": [
    "-> y1보다 y2가 t에 더 가까운 값임을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a35d1",
   "metadata": {},
   "source": [
    "## step05_02\n",
    "### Tensorflow: 평균 제곱 오차(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859c48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(t, y1)= tf.Tensor(1.875, shape=(), dtype=float64)\n",
      "MSE(t, y2)= tf.Tensor(0.25, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def MSE(y, t):\n",
    "    #square()은 제곱이다.\n",
    "    #reduce_mean()은 평균을 계산한다.\n",
    "    return tf.reduce_mean(tf.square(y-t)) #(y-t)**2\n",
    "\n",
    "t = np.array([1, 2, 3, 4])\n",
    "y1 = np.array([0.5, 1, 1.5, 2])\n",
    "print(\"MSE(t, y1)=\", MSE(t, y1))\n",
    "\n",
    "y2 = np.array([0.5, 1.5, 2.5, 3.5])\n",
    "print(\"MSE(t, y2)=\", MSE(t, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee69f1",
   "metadata": {},
   "source": [
    "## step05_03\n",
    "### tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb7e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(t, y1)= 1.875\n",
      "MSE(t, y2)= tf.Tensor(0.25, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# t = np.array([1, 2, 3, 4])\n",
    "# y1 = np.array([0.5, 1, 1.5, 2])\n",
    "t = tf.convert_to_tensor(t, dtype = tf.float32)# tf.convert_to_tensor는 list, ndarray 타입을 다음과 같이 tensor 타입으로 변경\n",
    "y1 = tf.convert_to_tensor(y1,dtype = tf.float32)\n",
    "\n",
    "MSE = tf.keras.losses.MeanSquaredError() #tf.keras.losses 모듈에 다양한 손실함수가 구현되어 있다.\n",
    "\n",
    "print(\"MSE(t, y1)=\", MSE(t, y1).numpy())\n",
    "\n",
    "y2 = np.array([0.5, 1.5, 2.5, 3.5])\n",
    "print(\"MSE(t, y2)=\", MSE(t, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0e480",
   "metadata": {},
   "source": [
    "# Step06 넘파이 단순 선형 회귀\n",
    "스칼라 입력을 갖는 단순 선형 회귀의 해를 넘파이를 이용해서 경사하강법(Gradient decent)으로 구현한다.\n",
    "\n",
    "입력 x를 갖고, 가중치 w와 바이어스 b를 갖는 선형 모델을 이용한다.\n",
    "\n",
    "훈련 데이터(x(i), t(i))를 이용해서 손실함수인 MSE를 경사하강법으로 반복적으로 최소화하는 w, b를 학습힌다.\n",
    "\n",
    "훈련 데이터를 한 번 적용하는 것을 1 에폭이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337f4f0",
   "metadata": {},
   "source": [
    "### 경사하강법\n",
    "경사하강법은 파라미터의 초기값 p(0) = (w(0), b(0))를 설정하고, 손실함수인 MSE에서 **그래디언트(변화율, 기울기, 경사) ∇E(w,b)**를 계산한다.\n",
    "\n",
    "반복적으로 파라미터를 갱신하여 손실함수 E(w,b)를 최소화하는 파라미터를 계산한다.\n",
    "\n",
    "학습률 lr는 0 < lr <= 1 범위의 값으로 그래디언트의 크기에 곱하여 한 번에 이동할 거리를 조절한다.\n",
    "<br><br><br>\n",
    "[수식6.3]은 편미분에 의한 평균 제곱 오차(MSE) 손실함수에 의한 그래디언트(변화율, 기울기, 경사) ∇E(w,b)계산이다!\n",
    "\n",
    "손실함수의 그래디언트는 수치미분, 텐서플로의 자동 미분을 사용하면 효율적으로 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793b6e",
   "metadata": {},
   "source": [
    "## step06_01\n",
    "### Numpy: 경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc89120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: w=  0.5422, b=  0.0055, loss8.810943726851852\n",
      "epoch=10: w=  0.8083, b=  0.0401, loss1.466715172963861\n",
      "epoch=20: w=  0.9169, b=  0.0540, loss0.24495255472001454\n",
      "epoch=30: w=  0.9612, b=  0.0594, loss0.04169519566872019\n",
      "epoch=40: w=  0.9793, b=  0.0615, loss0.00787178191488498\n",
      "epoch=50: w=  0.9867, b=  0.0621, loss0.0022347319688341234\n",
      "epoch=60: w=  0.9897, b=  0.0621, loss0.0012867496046894964\n",
      "epoch=70: w=  0.9910, b=  0.0619, loss0.001118931939796754\n",
      "epoch=80: w=  0.9916, b=  0.0617, loss0.0010810107035373918\n",
      "epoch=90: w=  0.9918, b=  0.0613, loss0.0010648090349303324\n",
      "epoch=100: w=  0.9919, b=  0.0610, loss0.0010523299085510528\n",
      "epoch=110: w=  0.9920, b=  0.0607, loss0.0010405782132124229\n",
      "epoch=120: w=  0.9921, b=  0.0603, loss0.0010290545002240247\n",
      "epoch=130: w=  0.9921, b=  0.0600, loss0.001017674500996345\n",
      "epoch=140: w=  0.9922, b=  0.0597, loss0.0010064230274573972\n",
      "epoch=150: w=  0.9922, b=  0.0593, loss0.0009952963963807077\n",
      "epoch=160: w=  0.9923, b=  0.0590, loss0.0009842928512196758\n",
      "epoch=170: w=  0.9923, b=  0.0587, loss0.0009734109685867998\n",
      "epoch=180: w=  0.9923, b=  0.0584, loss0.0009626493930231703\n",
      "epoch=190: w=  0.9924, b=  0.0580, loss0.0009520067927376391\n",
      "w=  0.9924, b=  0.0577, loss0.0009\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MSE(y, t):\n",
    "    return np.sum((y-t)**2)/t.size\n",
    "\n",
    "x = np.arange(12) #[0,1,2,3,4,5,6,7,8,9,10,11] #입력값\n",
    "t = np.arange(12) #목표값\n",
    "\n",
    "w = 0.5 #초기 값\n",
    "b = 0\n",
    "lr = 0.001 #학습률이다. 0 < lr <= 1 범위의 값으로 그래디언트의 크기에 곱하여 한 번에 이동할 거리를 조절한다.\n",
    "#lr = 0.01\n",
    "#0.01이 0.001보다 빨리 0으로 감소하는 것을 확인할 수 있다.\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(200):\n",
    "    y = w * x + b\n",
    "    \n",
    "#     dW = np.sum((y - t) * x) / (2 * x.size) #그래디언트(변화율, 기울기, 경사) 크기를 구함\n",
    "#     dB = np.sum(y - t) / (2 * x.size)\n",
    "    #수식 오류 변경!!\n",
    "    dW = np.sum((y - t) * x) * (2 / x.size) #그래디언트(변화율, 기울기, 경사) 크기를 구함\n",
    "    dB = np.sum(y - t) * (2 / x.size)\n",
    "    \n",
    "    w = w - lr * dW # update\n",
    "    b = b - lr * dB\n",
    "    \n",
    "    y = w * x + b # output을 계산한다.\n",
    "    loss = MSE(y, t) # 손실율을 계산한다. 이를 최소화하는 파라미터를 계산하는 중이다.\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    if not epoch % 10: #epoch가 10의 배수만큼 일때 마다 출력\n",
    "        print(\"epoch={}: w={:>8.4f}, b={:8.4f}, loss{}\".format(epoch, w, b, loss))\n",
    "\n",
    "print(\"w={:>8.4f}, b={:8.4f}, loss{:>.4f}\".format(w, b, loss))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8542ff",
   "metadata": {},
   "source": [
    "### 확률적 경사하강법\n",
    "확률적 경사하강법은 각 반복(epoch)에서 훈련 데이터 모두를 적용하지 않고\n",
    "\n",
    "일정 개수를 **샘플링**하여 경사하강법으로 학습한다.(샘플 크기를 1로 하면 최적해를 찾지 못할 수도 있으며 GPU 성능을 활용하지 못하는 단점이 있다.)\n",
    "\n",
    "일반적으로 일반 개수 이상의 배치 크기로 샘플링하는 **미니 배치** 학습으로 구현한다.\n",
    "\n",
    "미니 배치 확률적 경사하강법의 **장점은 지역 극값을 부분적으로 피할 수 있고**, 훈련 데이터가 아주 많을 때 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d209bd",
   "metadata": {},
   "source": [
    "## step06_02\n",
    "### Numpy: 미니배치에 의한 확률적 경사하강법(SGD)\n",
    "SGD를 numpy로 구현하여 가중치 w와 바이어스 b를 계산한다.<br><br>\n",
    "\n",
    "12개의 훈련 데이터가 있다.\n",
    "\n",
    "각 에폭마다 훈련데이터 (x, t)에서 K번(batch_size)개수를 랜덤으로 미니배치 데이터를 추출한다.\n",
    "\n",
    "추출한 x_batch, t_batch는 편미분 수식으로 그래디언트(dW, dB)를 계산하고 경사하강법으로 w,b를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf40b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: w=  0.6129, b=  0.0156, loss6.867475740512556\n",
      "epoch=10: w=  0.9584, b=  0.0624, loss0.06056227179961823\n",
      "epoch=20: w=  0.9892, b=  0.0655, loss0.0012287472144151658\n",
      "epoch=30: w=  0.9920, b=  0.0649, loss0.0008694579115736366\n",
      "epoch=40: w=  0.9917, b=  0.0640, loss0.001280454351855291\n",
      "epoch=50: w=  0.9916, b=  0.0628, loss0.0016222330391098443\n",
      "epoch=60: w=  0.9924, b=  0.0620, loss0.0010427662382586753\n",
      "epoch=70: w=  0.9919, b=  0.0611, loss0.0011332876872250026\n",
      "epoch=80: w=  0.9919, b=  0.0599, loss0.0008424657631537899\n",
      "epoch=90: w=  0.9931, b=  0.0592, loss0.0010356823855944967\n",
      "w=  0.9921, b=  0.0579, loss0.0011\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def MSE(y, t):\n",
    "    return np.sum((y-t)**2)/t.size\n",
    "\n",
    "x = np.arange(12)\n",
    "t = np.arange(12)\n",
    "\n",
    "w = 0.5\n",
    "b = 0\n",
    "lr = 0.001\n",
    "loss_list = []\n",
    "\n",
    "train_size = t.size # 12\n",
    "batch_size = 4\n",
    "K = train_size // batch_size # 3\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss = 0\n",
    "    for step in range(K): # K = train_size // batch_size == 3번 동안 \n",
    "        mask = np.random.choice(train_size, batch_size) # 미니배치 데이터를 랜덤으로 추출-> 0~11에서 4개를 추출한다.\n",
    "        \n",
    "        x_batch = x[mask] #mask 자리에 있는 값들을 x_batch와 t_batch에 넣는다.\n",
    "        t_batch = t[mask]\n",
    "        \n",
    "        y = w * x_batch + b\n",
    "#         dW = np.sum((y-t_batch) * x_batch) /(2*batch_size) #gradients\n",
    "#         dB = np.sum((y-t_batch)/(2*batch_size))\n",
    "        #수식 오류 변경!!\n",
    "        dW = np.sum((y - t_batch) * t_batch) * (2 / batch_size) #그래디언트(변화율, 기울기, 경사) 크기를 구함\n",
    "        dB = np.sum(y - t_batch) * (2 / batch_size)\n",
    "\n",
    "\n",
    "        w = w - lr * dW #update\n",
    "        b = b - lr * dB\n",
    "        \n",
    "        y = w * x_batch + b #output 계산하기\n",
    "        loss += MSE(y, t_batch) #loss율 계산하기\n",
    "    loss /= K #평균 loss\n",
    "    loss_list.append(loss)\n",
    "    if not epoch % 10: #epoch가 10의 배수만큼 일때 마다 출력\n",
    "        print(\"epoch={}: w={:>8.4f}, b={:8.4f}, loss{}\".format(epoch, w, b, loss))\n",
    "\n",
    "print(\"w={:>8.4f}, b={:8.4f}, loss{:>.4f}\".format(w, b, loss))\n",
    "plt.plot(loss_list)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234c85b",
   "metadata": {},
   "source": [
    "-> 각각의 에폭에서 K번 batch_size의 미니배치를 수행하면 훈련 데이터 전체를 한번(에폭) 처리한 효과를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa57a1",
   "metadata": {},
   "source": [
    "# Step07 자동 미분 계산\n",
    "텐서플로의 자동 미분에 대해서 설명한다.\n",
    "\n",
    "자동 미분은 **연쇄 법칙을 사용**하며 다층 신경망 학습에서 필요한 **오차역전파(back-propagation) 알고리즘의 미분을 효율적으로 계산**한다.\n",
    "\n",
    "자동 미분을 사용하면 경사하강법에 필요한 **그래디언트를 자동으로 계산**할 수 있다.\n",
    "\n",
    "<br><br>\n",
    "tf.GradientTape로 연산을 테이프에 기록하고, GradientTape.gradient()로 기록된 연산의 미분을 자동으로 계산한다.\n",
    "\n",
    "테이프에 기록하는 연산은 텐서 변수이어야 하며, 상수 텐서는 테이프에서 추적할 수 있도록 tf.GradientTape.watch()로 설정해야 한다.\n",
    "\n",
    "GradientTape.gradient()는 한번 호출하면 테이프에 기록된 자원이 해제되므로, 자원을 유지하여 한번 이상 호출하려면 tf.GradientTape(persistent = True)로 그래디언트 테이프를 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d2374",
   "metadata": {},
   "source": [
    "## step07_01\n",
    "### 자동 미분 계산 1: tf.GradientTape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c896aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx= 2.0\n",
      "dy= 3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#trainable = True인 \"watched\"로 설정된 텐서 변수 x, y를 생성한다.\n",
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = x ** 2 + y ** 2 #수식을 기록한다.\n",
    "    \n",
    "#z의 x와 y에 대한 편미분 dx, dy를 자동으로 계산하고,\n",
    "#dx.numpy()와 dy.numpt() 함수는 텐서 dx, dy의 넘파이 값을 계산한다.\n",
    "dx, dy = tape.gradient(z,[x,y])\n",
    "\n",
    "print('dx=', x.numpy())\n",
    "print('dy=', y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814cb88",
   "metadata": {},
   "source": [
    "## step07_04\n",
    "### 자동 미분 계산 4: 2차 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6233fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy= 27.0\n",
      "dy2= 18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape2:\n",
    "    with tf.GradientTape() as tape1:\n",
    "        y = x ** 3 #수식을 tape1에 기록\n",
    "        dy = tape1.gradient(y, x) #tape1로 수식 y의  x에 대한 미분을 dy에 계산한다.\n",
    "dy2 = tape2.gradient(dy, x) #tape2로 1차 미분 dy의 x에 대한 미분을 dy2에 계산한다.\n",
    "\n",
    "print('dy=', dy.numpy())\n",
    "print('dy2=', dy2.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
