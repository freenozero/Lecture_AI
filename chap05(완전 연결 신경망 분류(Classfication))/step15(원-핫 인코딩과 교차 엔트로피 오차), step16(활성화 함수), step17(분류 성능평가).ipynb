{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3572cf",
   "metadata": {},
   "source": [
    "# Step15 원-핫 인코딩과 교차 엔트로피 오차\n",
    "\n",
    "2장은 목표값 t와 모델의 예측값 y 사이의 평균제곱오차(mse) 손실함수를 사용했다.(분류에서도 MSE를 사용가능 하긴 함)\n",
    "\n",
    "하지만 여기서는 분류에서 주로 사용하는 손실함수를 설명한다.\n",
    "1. 원-핫 인코딩\n",
    "2. 카탈로그 교차 엔트로피 오차(CCE)\n",
    "3. 이진 교차 엔트로피 오차(BCE)의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8c688",
   "metadata": {},
   "source": [
    "## 1. 원-핫 인코딩\n",
    "원-핫 인코딩은 분류에서 목표값 레이블을 표현하는 방법 중 하나로,\n",
    "\n",
    "각 카테고리에 대한 원-핫 인코딩은 부여받은 정수의 인덱스 위치만 1이고 나머지는 0을 갖는 것이다.\n",
    "\n",
    "<정수 카테고리에 대한 원-핫 인코딩 이진 행렬을 반환>\n",
    "```python\n",
    "#1\n",
    "tf.one_hot(indices, depth, ...) #indices의 정수를 depth 깊이로 원-핫 인코딩한 행렬의 텐서를 반환한다.\n",
    "#2\n",
    "tf.keras.utils.to_categorical(y, num_classes = None, dtype='float32')\n",
    "#정수의 클래스 레이블 벡터(y)를 클래스의 개수(num_classes)로 원-핫 인코딩한 넘파이 행렬을 반환한다.\n",
    "```\n",
    "<br><br>\n",
    "## step15_01\n",
    "### 원-핫 인코딩: tf.one_hot(), tf.keras.utils.to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20eabeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= [0 1 2 3 4 5 6 7 8 9]\n",
      "y1= [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "y2= [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "y = np.arange(10)\n",
    "print(\"y=\", y)\n",
    "\n",
    "y1 = tf.keras.utils.to_categorical(y)\n",
    "print(\"y1=\", y1)\n",
    "\n",
    "y2 = tf.one_hot(y, depth=10) #depth를 주어줘야한다.\n",
    "print(\"y2=\", y2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240046d",
   "metadata": {},
   "source": [
    "## 2. 카테고리 교차 엔트로피 오차\n",
    "p.114!!-> [수식 15.1], [수식 15.2]\n",
    "\n",
    "카테고리 교차 엔트로피 함수는 여러 클래스 중에서 어느 하나의 클래스에 속지를 결정하는 다중 분류에 사용한다.\n",
    "\n",
    "출력층은 클래스의 개수만큼의 뉴런을 가지며, 출력층의 활성화 함수는 softmax를 사용하고, 출력 뉴런 중에서 **최대 예측 값을 갖는 뉴런에 대한 인덱스의 클래스로 분류**한다.\n",
    "<br><br>\n",
    "1. 카테고리 교차 엔트로피: 원-핫 인코딩 목표값\n",
    "```python\n",
    "CCE = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(optimizer='rmsprop', loss=CCE, metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "tf.keras.losses.CategoricalCrossentropy()는 다중 클래스 분류에서 **목표값이 원-핫 인코딩 되었을 때 교차 엔트로피 오차를 계산**한다.\n",
    "<br><br><br>\n",
    "2. 최소 카테고리 교차 엔트로피: 정수 레이블 인코딩\n",
    "```python\n",
    "CCE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer='rmsprop', loss=CCE, metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "tf.keras.losses.SparseCategoricalCrossentropy()는 다중 클래스 분류에서 **목표값이 정수 레이블로 인코딩 되었을 때 교차 엔트로피 오차를 계산**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87097bc6",
   "metadata": {},
   "source": [
    "## step15_02\n",
    "### tf.keras.losses.CategoricalCrossentropy()\n",
    "1. 카테고리 교차 엔트로피: 원-핫 인코딩 목표값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2efc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE(t[i], y[0])\n",
      "CCE(t[0], y[0])= 0.916290731874155\n",
      "CCE(t[1], y[0])= 1.203972804325936\n",
      "CCE(t[2], y[0])= 1.6094379124341003\n",
      "CCE(t[3], y[0])= 2.3025850929940455\n",
      "CCE(t[i], y[1])\n",
      "CCE(t[0], y[1])= 2.3025850929940455\n",
      "CCE(t[1], y[1])= 1.203972804325936\n",
      "CCE(t[2], y[1])= 1.6094379124341003\n",
      "CCE(t[3], y[1])= 0.916290731874155\n",
      "CCE(np.vstack((t[1], t[1])), y)= 1.203972804325936\n",
      "[[0 1 0 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "CCE = tf.keras.losses.CategoricalCrossentropy()\n",
    "# t: 목표값, y: 원하는 출력값\n",
    "t= np.array([[1,   0,   0,   0],   #t[0]\n",
    "             [0,   1,   0,   0],   #t[1]\n",
    "             [0,   0,   1,   0],   #t[2]\n",
    "             [0,   0,   0,   1]])  #t[3]\n",
    "\n",
    "y =np.array([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
    "             [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
    "#1\n",
    "print(\"CCE(t[i], y[0])\")\n",
    "print(\"CCE(t[0], y[0])=\", CCE(t[0], y[0]).numpy() ) \n",
    "print(\"CCE(t[1], y[0])=\", CCE(t[1], y[0]).numpy() )\n",
    "print(\"CCE(t[2], y[0])=\", CCE(t[2], y[0]).numpy() )\n",
    "print(\"CCE(t[3], y[0])=\", CCE(t[3], y[0]).numpy() ) \n",
    "\n",
    "#2\n",
    "print(\"CCE(t[i], y[1])\")\n",
    "print(\"CCE(t[0], y[1])=\", CCE(t[0], y[1]).numpy() ) \n",
    "print(\"CCE(t[1], y[1])=\", CCE(t[1], y[1]).numpy() )\n",
    "print(\"CCE(t[2], y[1])=\", CCE(t[2], y[1]).numpy() )\n",
    "print(\"CCE(t[3], y[1])=\", CCE(t[3], y[1]).numpy() )\n",
    "\n",
    "#3\n",
    "print(\"CCE(np.vstack((t[1], t[1])), y)=\",\n",
    "       CCE(np.vstack((t[1], t[1])), y).numpy() )\n",
    "\n",
    "#이해 못하겠엉!\n",
    "print(np.vstack((t[1],t[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325fb3e7",
   "metadata": {},
   "source": [
    "1. y[0]은 t[0](CCE(t[0], y[0])),\n",
    "2. y[1]은 t[3](CCE(t[3], y[1]))과 교차엔트로피 오차가 제일 적다.\n",
    "\n",
    "-> 2개의 미니배치 출력 y의 목표값이 np.vstack(t[1], t[1])일 때 교차 엔트로피 오차는 1.20이다.\n",
    "\n",
    "즉, 교차 엔트로피의 평균 (CEE(y[0], t[0]) + CEE(y[1], t[1]))/2 이다.\n",
    "\n",
    "<br><br>\n",
    "-> y[0]은 t[0]과 오차가 가장 적고 y[1]은 t[3]과오차가 가작 작다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27f528",
   "metadata": {},
   "source": [
    "## step15_02\n",
    "### tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "2. 최소 카테고리 교차 엔트로피: 정수 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ea7c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCE(t[i], y[0])\n",
      "SCE(t[0], y[0])= 0.91629076\n",
      "SCE(t[1], y[0])= 1.2039728\n",
      "SCE(t[2], y[0])= 1.609438\n",
      "SCE(t[3], y[0])= 2.3025851\n",
      "SCE(t[i], y[1])\n",
      "SCE(t[0], y[1])= 2.3025851\n",
      "SCE(t[1], y[1])= 1.2039728\n",
      "SCE(t[2], y[1])= 1.609438\n",
      "SCE(t[3], y[1])= 0.91629076\n",
      "SCE(tf.stack((t[1], t[1])), y)= 1.2039728\n",
      "1.4067054\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "SCE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "t = tf.convert_to_tensor([0, 1, 2, 3])\n",
    "y =tf.convert_to_tensor([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
    "                         [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
    "\n",
    "#1\n",
    "print(\"SCE(t[i], y[0])\")\n",
    "print(\"SCE(t[0], y[0])=\", SCE(t[0], y[0]).numpy() ) \n",
    "print(\"SCE(t[1], y[0])=\", SCE(t[1], y[0]).numpy() )\n",
    "print(\"SCE(t[2], y[0])=\", SCE(t[2], y[0]).numpy() )\n",
    "print(\"SCE(t[3], y[0])=\", SCE(t[3], y[0]).numpy() ) \n",
    "\n",
    "#2\n",
    "print(\"SCE(t[i], y[1])\")\n",
    "print(\"SCE(t[0], y[1])=\", SCE(t[0], y[1]).numpy() ) \n",
    "print(\"SCE(t[1], y[1])=\", SCE(t[1], y[1]).numpy() )\n",
    "print(\"SCE(t[2], y[1])=\", SCE(t[2], y[1]).numpy() )\n",
    "print(\"SCE(t[3], y[1])=\", SCE(t[3], y[1]).numpy() )\n",
    "\n",
    "#3\n",
    "print(\"SCE(tf.stack((t[1], t[1])), y)=\",\n",
    "       SCE(tf.stack((t[1], t[1])), y).numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40743d5a",
   "metadata": {},
   "source": [
    "2개의 미니배치 출력 y의 목표값이 np.vstack((t[1],t[1]))일 때, 교차 엔트로피 오차는 1.20이다.\n",
    "\n",
    "즉, 교차 엔트로피의 평균'(SCE(t[1], y[0]) + SCE(t[1],y[1]))/2'이다.\n",
    "<br><br>\n",
    "\n",
    "-> y[0]은 t[0]과 오차가 가장 적고 y[1]은 t[3]과오차가 가작 작다.\n",
    "<br><br><br>\n",
    "\n",
    "## 3. 이진 교차 엔트로피 오차\n",
    "p. 117: 수식 참고!\n",
    "\n",
    "이진 교차 엔트로피 오차 손실함수는 출력층의 활성화 함수가 sigmoid를 사용할 때 주로 사용하며\n",
    "\n",
    "훈련 데이터의 목표값에 출력층의 레이블을 속함(1), 속하지 않음(0)으로 표현한다.\n",
    "<br><br>\n",
    "\n",
    "1. 출력층이 1뉴런(유닛)이면 1-레이블을 분류할 수 있다. 각 훈련 데이터의 목표값은 0 또는 1로 표현한다.\n",
    "2. 출력층이 2뉴런(유닛)이면 2-레이블을 분류할 수 있다. 각 훈련 데이터의 목표값은 [0,0], [0,1], [1,0], [1,1]로 4개의 클래스로 분류할 수 있다.\n",
    "\n",
    "여러 개의 뉴런(유닛)을 갖는 출력층으로 다중 레이블 분류를 할 수 있다. 출력층의 각 뉴런의 예측값이 1에 가까운지, 0에 가까운지에 따라 존재를 판단한다.\n",
    "```python\n",
    "BCE = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer='rmsprop', loss=BCE, metrics=['accuracy'])\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accruacy'])\n",
    "```\n",
    "tf.keras.losses.BinaryCrossentropy()는 다중 레이블 분류에서 이중 교차 엔트로피 오차를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e587b",
   "metadata": {},
   "source": [
    "## step15_04\n",
    "### 이진 교차 엔트로피1: tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d921b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE(t[i], y[0])\n",
      "BCE(t[0], y[0])= 0.4003672784541813\n",
      "BCE(t[1], y[0])= 0.5108254397382338\n",
      "BCE(t[2], y[0])= 0.6455745187904711\n",
      "BCE(t[3], y[0])= 0.8483069443724252\n",
      "BCE(t[i], y[1])\n",
      "BCE(t[0], y[1])= 0.8483069443724252\n",
      "BCE(t[1], y[1])= 0.5108254397382338\n",
      "BCE(t[2], y[1])= 0.6455745187904711\n",
      "BCE(t[3], y[1])= 0.40036727845418124\n",
      "BCE(np.vstack((t[0], t[0])), y)= 0.6243371114133032\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BCE = tf.keras.losses.BinaryCrossentropy()\n",
    "t= np.array([[1,   0,   0,   0],   #t[0]\n",
    "             [0,   1,   0,   0],   #t[1]\n",
    "             [0,   0,   1,   0],   #t[2]\n",
    "             [0,   0,   0,   1]])  #t[3]\n",
    "\n",
    "y =np.array([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
    "             [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
    "#1\n",
    "print(\"BCE(t[i], y[0])\")\n",
    "print(\"BCE(t[0], y[0])=\", BCE(t[0], y[0]).numpy() )\n",
    "print(\"BCE(t[1], y[0])=\", BCE(t[1], y[0]).numpy() )\n",
    "print(\"BCE(t[2], y[0])=\", BCE(t[2], y[0]).numpy() )\n",
    "print(\"BCE(t[3], y[0])=\", BCE(t[3], y[0]).numpy() ) \n",
    "\n",
    "#2\n",
    "print(\"BCE(t[i], y[1])\")\n",
    "print(\"BCE(t[0], y[1])=\", BCE(t[0], y[1]).numpy() ) \n",
    "print(\"BCE(t[1], y[1])=\", BCE(t[1], y[1]).numpy() )\n",
    "print(\"BCE(t[2], y[1])=\", BCE(t[2], y[1]).numpy() )\n",
    "print(\"BCE(t[3], y[1])=\", BCE(t[3], y[1]).numpy() )\n",
    "\n",
    "#3\n",
    "print(\"BCE(np.vstack((t[0], t[0])), y)=\",\n",
    "       BCE(np.vstack((t[0], t[0])), y).numpy() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6dd585",
   "metadata": {},
   "source": [
    "-> BCE(np.vstack((t[0], t[0])), y).numpy()가 0.62이다.\n",
    "\n",
    "즉, 이진 교차 엔트로피의 평균은 (BCE(t[0],y[0]) + BCE(t[0],y[1]))/2이다.\n",
    "<br><br>\n",
    "-> y[0]은 t[0]과 오차가 가장 적고 y[1]은 t[3]과오차가 가작 작다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4512ab8",
   "metadata": {},
   "source": [
    "## step15_05\n",
    "### 이진 교차 엔트로피2: tf.keras.losses.BinaryCrossentropy()\n",
    "step15_04 차이점 -> t가 이진 인코딩(원-핫 인코딩)이 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9325c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE(t[i], y[0])\n",
      "BCE(t[0], y[0])= 0.6121916959319459\n",
      "BCE(t[1], y[0])= 0.8573989362682357\n",
      "BCE(t[2], y[0])= 1.194880440902427\n",
      "BCE(t[3], y[0])= 1.0601313618501897\n",
      "BCE(t[i], y[1])\n",
      "BCE(t[0], y[1])= 1.0601313618501897\n",
      "BCE(t[1], y[1])= 0.8573989362682357\n",
      "BCE(t[2], y[1])= 0.7469407749841832\n",
      "BCE(t[3], y[1])= 0.6121916959319459\n",
      "BCE(np.vstack((t[0], t[0])), y)= 0.8361615288910678\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BCE = tf.keras.losses.BinaryCrossentropy()\n",
    "t= np.array([[1,   1,   0,   0],   #t[0]\n",
    "             [0,   1,   1,   0],   #t[1]\n",
    "             [0,   0,   1,   1],   #t[2]\n",
    "             [0,   1,   0,   1]])  #t[3]\n",
    "\n",
    "y =np.array([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
    "             [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
    "#1\n",
    "print(\"BCE(t[i], y[0])\")\n",
    "print(\"BCE(t[0], y[0])=\", BCE(t[0], y[0]).numpy() ) \n",
    "print(\"BCE(t[1], y[0])=\", BCE(t[1], y[0]).numpy() )\n",
    "print(\"BCE(t[2], y[0])=\", BCE(t[2], y[0]).numpy() )\n",
    "print(\"BCE(t[3], y[0])=\", BCE(t[3], y[0]).numpy() ) \n",
    "\n",
    "#2\n",
    "print(\"BCE(t[i], y[1])\")\n",
    "print(\"BCE(t[0], y[1])=\", BCE(t[0], y[1]).numpy() ) \n",
    "print(\"BCE(t[1], y[1])=\", BCE(t[1], y[1]).numpy() )\n",
    "print(\"BCE(t[2], y[1])=\", BCE(t[2], y[1]).numpy() )\n",
    "print(\"BCE(t[3], y[1])=\", BCE(t[3], y[1]).numpy() )\n",
    "\n",
    "#3\n",
    "print(\"BCE(np.vstack((t[0], t[0])), y)=\",\n",
    "       BCE(np.vstack((t[0], t[0])), y).numpy() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d6de2",
   "metadata": {},
   "source": [
    "# Step16 활성화 함수\n",
    "**p.122!!!**\n",
    "\n",
    "일반적으로 뉴런의 출력은 y = f(WX + b)와 같이 활성화 함수(f())에 의해 뉴런의 출력을 제어한다.\n",
    "\n",
    "<종류> \n",
    "1. linear: 입력 x를 그대로 출력한다.\n",
    "2. sigmoid: (0, 1) 범위의 값으로 변환한다.\n",
    "3. tanh: (-1, 1) 범위의 값으로 변환한다.\n",
    "4. relu: 양수는 그대로, 음수는 0으로 변환한다.\n",
    "5. LeakyReLU: 음수여도 alpha 값에 x를 곱해서 변환한다.\n",
    "6. softmax: 지수함수를 사용하여 입력 벡터 x를 확률로 변환한다.\n",
    "\n",
    "<사용법>\n",
    "\n",
    "완전 연결층을 생성하는 Dense 층을 생성할 때, activation 인수에 함수 이름 또는 문자열('linear', 'sigmoid', 'tanh', 'softmax' 등)로 활성화 함수를 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8c621",
   "metadata": {},
   "source": [
    "## step16_01\n",
    "### 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a91c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1= [-10.  -1.   0.   1.  10.]\n",
      "y2= [4.5397868e-05 2.6894143e-01 5.0000000e-01 7.3105860e-01 9.9995458e-01]\n",
      "y3= [-1.        -0.7615942  0.         0.7615942  1.       ]\n",
      "y4= [ 0.  0.  0.  1. 10.]\n",
      "y5= [-1.  -0.1  0.   1.  10. ]\n",
      "y6= [[2.0607716e-09 1.6698603e-05 4.5391513e-05 1.2338691e-04 9.9981457e-01]]\n",
      "sum(y6)= 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.constant([-10, -1.0, 0.0, 1.0, 10], dtype = tf.float32)\n",
    "\n",
    "y1 = tf.keras.activations.linear(x) \n",
    "y2 = tf.keras.activations.sigmoid(x)\n",
    "y3 = tf.keras.activations.tanh(x)\n",
    "y4 = tf.keras.activations.relu(x)\n",
    "y5 = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "y6 = tf.keras.activations.softmax(tf.reshape(x, shape=(1, -1)))\n",
    "\n",
    "##linear = tf.keras.activations.get('linear')\n",
    "##y1 = linear(x)\n",
    "##\n",
    "##sigmoid = tf.keras.activations.get('sigmoid')\n",
    "##y2 = sigmoid(x)\n",
    "##\n",
    "##tanh = tf.keras.activations.get('tanh')\n",
    "##y3 = tanh(x)\n",
    "##\n",
    "##relu = tf.keras.activations.get('relu')\n",
    "##y4 = relu(x)\n",
    "##\n",
    "##y5 = relu(x, alpha=0.1) # LeakyReLU\n",
    "##softmax = tf.keras.activations.get('softmax')\n",
    "##y6 = softmax(tf.reshape(x, shape=(1, -1)))\n",
    "\n",
    "print(\"y1=\", y1.numpy())\n",
    "print(\"y2=\", y2.numpy())\n",
    "print(\"y3=\", y3.numpy())\n",
    "print(\"y4=\", y4.numpy())\n",
    "print(\"y5=\", y5.numpy())\n",
    "print(\"y6=\", y6.numpy())\n",
    "print(\"sum(y6)=\", np.sum(y6.numpy())) # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14643772",
   "metadata": {},
   "source": [
    "# Step17 분류 성능평가\n",
    "1. 정확도(accuracy): 전체에서 y_true, y_pred의 매칭 개수의 비율이다.\n",
    "2. 정밀도(precision): Positive로 예측한 것 중에서 실제 Positive인 비율이다.\n",
    "3. 재현율(recall): 실제 Positive인 것 중에서 Positive로 예측한 비율이다.\n",
    "**P.123**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
